crawler:
1. distinct url —> maybe using `set()`
2. consider 500 req/day ( —> create multiple account/API , devide the task using multithreading/multiprocessing )
3. save the urls from crawler —> maybe saved on database

virustotal scanner:
1. scan the urls
2. create report based on return value


problems:
1. site/app that using login —> maybe create some like (LSR) login sequence recorder
